{
  "name": "Workflow A: Universal Extractor",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "extract",
        "responseMode": "responseNode",
        "options": {
          "responseTimeout": 1800000
        },
        "authentication": "headerAuth"
      },
      "id": "webhook-extract",
      "name": "Webhook: Extract Content",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        240,
        460
      ],
      "webhookId": "universal-extractor-webhook",
      "credentials": {
        "httpHeaderAuth": {
          "id": "webhook-api-key",
          "name": "webhook-api-key"
        }
      }
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": false,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "has-binary",
                    "leftValue": "={{ Object.keys($binary).length > 0 }}",
                    "rightValue": true,
                    "operator": {
                      "type": "boolean",
                      "operation": "true"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.4,
      "position": [
        680,
        200
      ],
      "id": "validate-binary",
      "name": "Validate Binary"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{ { \"error\": \"No file provided\", \"status\": 400 } }}"
      },
      "id": "error-no-file",
      "name": "Error: No File",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1280,
        620
      ]
    },
    {
      "parameters": {
        "jsCode": "const crypto = require('crypto');\n\nfor (const item of $input.all()) {\n  if (item.binary) {\n    // Find the first binary data field (could be 'data', 'file', or any other name)\n    const binaryKey = Object.keys(item.binary)[0];\n    \n    if (binaryKey && item.binary[binaryKey]) {\n      const timestamp = Date.now();\n      const random = crypto.randomBytes(4).toString('hex');\n      const filePrefix = `${timestamp}_${random}_`;\n      \n      const fileName = item.binary[binaryKey].fileName || 'upload';\n      const fileExt = fileName.split('.').pop().toLowerCase();\n      \n      // Normalize to 'data' field for consistent downstream processing\n      if (binaryKey !== 'data') {\n        item.binary.data = item.binary[binaryKey];\n        delete item.binary[binaryKey];\n      }\n      \n      // Set binary.data.fileName to include the prefix\n      const prefixedFileName = `${filePrefix}input.${fileExt}`;\n      item.binary.data.fileName = prefixedFileName;\n      \n      // Store metadata in json\n      item.json.filePrefix = filePrefix;\n      item.json.fileExtension = fileExt;\n      item.json.originalFileName = fileName;\n      item.json.timestamp = timestamp;\n    }\n  }\n}\n\nreturn $input.all();"
      },
      "id": "set-file-prefix",
      "name": "Set Binary Filename",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1120,
        300
      ]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "pdf-check",
                    "leftValue": "={{ $json.fileExtension }}",
                    "rightValue": "pdf",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "pptx-check",
                    "leftValue": "={{ $json.fileExtension }}",
                    "rightValue": "pptx",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "docx-check",
                    "leftValue": "={{ $json.fileExtension }}",
                    "rightValue": "docx",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "image-check",
                    "leftValue": "={{ ['png', 'jpg', 'jpeg'].includes($json.fileExtension) }}",
                    "rightValue": true,
                    "operator": {
                      "type": "boolean",
                      "operation": "true"
                    }
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "excel-check",
                    "leftValue": "={{ ['xlsx', 'xls', 'xlsm', 'csv'].includes($json.fileExtension) }}",
                    "rightValue": true,
                    "operator": {
                      "type": "boolean",
                      "operation": "true"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.4,
      "position": [
        1500,
        300
      ],
      "id": "switch-by-filetype",
      "name": "Switch by File Type"
    },
    {
      "parameters": {
        "operation": "write",
        "fileName": "=/tmp/n8n_processing/{{ $binary.data.fileName }}",
        "options": {}
      },
      "id": "write-temp-file",
      "name": "Write Temp File",
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        1720,
        300
      ]
    },
    {
      "parameters": {
        "command": "=pdftoppm -png -r 300 \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}input.pdf\" \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}page\""
      },
      "id": "extract-images",
      "name": "Extract Images",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2160,
        300
      ]
    },
    {
      "parameters": {
        "command": "=libreoffice --headless --convert-to pdf \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}input.pptx\" --outdir /tmp/n8n_processing"
      },
      "id": "convert-pptx-to-pdf",
      "name": "Convert PPTX to PDF",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        1940,
        220
      ]
    },
    {
      "parameters": {
        "command": "=libreoffice --headless --convert-to pdf \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}input.docx\" --outdir /tmp/n8n_processing"
      },
      "id": "convert-docx-to-pdf",
      "name": "Convert DOCX to PDF",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        1940,
        380
      ]
    },
    {
      "parameters": {
        "command": "=cp \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}input.{{ $json.fileExtension }}\" \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}page-1.png\""
      },
      "id": "copy-single-image",
      "name": "Copy Single Image",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        1940,
        540
      ]
    },
    {
      "parameters": {
        "command": "=libreoffice --headless --convert-to pdf \"/tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}input.{{ $node[\"Set Binary Filename\"].json[\"fileExtension\"] }}\" --outdir /tmp/n8n_processing"
      },
      "id": "convert-excel-to-pdf",
      "name": "Convert Excel to PDF",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        1940,
        660
      ]
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{ { \"error\": \"Unsupported file type: \" + $json.fileExtension, \"status\": 400 } }}"
      },
      "id": "error-unsupported-type",
      "name": "Error: Unsupported Type",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1940,
        860
      ]
    },
    {
      "parameters": {
        "command": "=ls /tmp/n8n_processing/{{ $node[\"Set Binary Filename\"].json[\"filePrefix\"] }}page-*.png"
      },
      "id": "list-generated-images",
      "name": "List Generated Images",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2380,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "const files = $input.all()[0].json.stdout.split('\\n').filter(f => f.trim() !== '');\nconst filePrefix = $('Set Binary Filename').all()[0].json.filePrefix;\nconst originalFileName = $('Set Binary Filename').all()[0].json.originalFileName;\n\nreturn files.map((filePath, index) => {\n  const fileName = filePath.split('/').pop();\n  return {\n    json: {\n      pageNumber: index + 1,\n      fileName: fileName,\n      filePath: filePath,\n      originalFile: originalFileName,\n      filePrefix: filePrefix\n    }\n  };\n});"
      },
      "id": "prepare-file-list",
      "name": "Prepare Generated File List",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2600,
        300
      ]
    },
    {
      "parameters": {
        "executeOnce": false,
        "command": "=tesseract \"{{ $json.filePath }}\" stdout -l eng+ara --oem 3 --psm 3"
      },
      "id": "ocr-processing",
      "name": "OCR Processing",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2820,
        220
      ],
      "executeOnce": false
    },
    {
      "parameters": {
        "executeOnce": false,
        "command": "=curl -v --retry 3 --retry-delay 2 -X POST -H \"Content-Type: application/json\" -d \"{\\\"filePath\\\": \\\"{{ $json.filePath }}\\\"}\" http://florence:5000/analyze"
      },
      "id": "florence-vision-analysis",
      "name": "Florence Vision Analysis",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2820,
        380
      ]
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "id": "merge-vision-ocr",
      "name": "Merge Vision & OCR",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        3040,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "const items = $input.all();\nconst results = [];\n\nconst ocrItems = $('OCR Processing').all();\nconst visionItems = $('Florence Vision Analysis').all();\nconst metaItems = $('Prepare Generated File List').all();\n\nfor (let i = 0; i < items.length; i++) {\n  const ocrText = ocrItems[i]?.json?.stdout || '';\n  const visionText = visionItems[i]?.json?.stdout || '';\n  const meta = metaItems[i]?.json || {};\n  \n  let visionData = {};\n  try {\n    visionData = JSON.parse(visionText);\n  } catch (e) {\n    visionData = { raw: visionText };\n  }\n  \n  const text = ocrText;\n  const wordCount = text.split(/\\s+/).length;\n  const complexityScore = (wordCount < 50) ? 0.8 : 0.2;\n\n  results.push({\n    json: {\n      ...meta,\n      extractedText: text,\n      visionAnalysis: visionData,\n      wordCount,\n      complexityScore,\n      isDiagram: complexityScore > 0.5\n    }\n  });\n}\n\nreturn results;"
      },
      "id": "parse-ocr",
      "name": "Parse OCR & Vision",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3260,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "const pages = $input.all();\nconst filePrefix = pages[0]?.json?.filePrefix || 'unknown';\nconst originalFile = pages[0]?.json?.originalFile || 'unknown';\n\nconst fullText = pages.map(p => p.json.extractedText).join('\\n\\n');\nconst totalWords = pages.reduce((sum, p) => sum + p.json.wordCount, 0);\nconst hasDiagrams = pages.some(p => p.json.isDiagram);\n\nconst result = {\n  filePrefix,\n  originalFileName: originalFile,\n  totalPages: pages.length,\n  totalWords,\n  hasDiagrams,\n  fullDocument: fullText,\n  pages: pages.map(p => ({\n    pageNumber: p.json.pageNumber,\n    text: p.json.extractedText,\n    wordCount: p.json.wordCount,\n    visionAnalysis: p.json.visionAnalysis,\n    isDiagram: p.json.isDiagram\n  }))\n};\n\nreturn [{ json: result }];"
      },
      "id": "aggregate-pages",
      "name": "Aggregate Pages",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3480,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "respond-success",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        3700,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseCode": 400
        }
      },
      "id": "respond-error-no-file",
      "name": "Respond Error",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1500,
        620
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseCode": 400
        }
      },
      "id": "respond-error-unsupported",
      "name": "Respond Error Type",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        2160,
        860
      ]
    },
    {
      "parameters": {
        "command": "curl -sf --max-time 5 http://florence:5000/health && curl -sf --max-time 5 http://ollama:11434/ && curl -sf --max-time 5 http://qdrant:6333/healthz"
      },
      "id": "services-health-check",
      "name": "Services Health Check",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        460,
        460
      ],
      "continueOnFail": true
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "health-check-pass",
                    "leftValue": "={{ $json.exitCode }}",
                    "rightValue": 0,
                    "operator": {
                      "type": "number",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.4,
      "position": [
        680,
        460
      ],
      "id": "check-health-status",
      "name": "Check Health Status"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{ { \"error\": \"Service Dependency Check Failed. One or more services (Florence, Ollama, Qdrant) are unavailable.\", \"status\": 503, \"details\": $json } }}"
      },
      "id": "set-service-error",
      "name": "Set Service Error",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        680,
        680
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseCode": 503
        }
      },
      "id": "respond-error-service",
      "name": "Respond Error Service",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        900,
        680
      ]
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "id": "merge-health-data",
      "name": "Merge Health & Data",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        900,
        460
      ]
    },
    {
      "parameters": {
        "jsCode": "const crypto = require('crypto');\nconst https = require('https');\n\n// Parse credentials from connection string (mirrors blobstorage.js approach)\nconst connectionString = $env.AZURE_STORAGE_CONNECTION_STRING || $env.AZURE_BLOB_CONNECTION_STRING;\nlet accountName, accountKey;\nif (connectionString) {\n  accountName = connectionString.match(/AccountName=([^;]+)/)?.[1];\n  accountKey  = connectionString.match(/AccountKey=([^;]+)/)?.[1];\n}\n// Fallback to individual env vars if connection string not set\nif (!accountName) accountName = $env.AZURE_STORAGE_ACCOUNT_NAME || 'unificdmpblob';\nif (!accountKey)  accountKey  = $env.AZURE_STORAGE_ACCOUNT_KEY;\n\nif (!accountKey) {\n  throw new Error(\n    'Azure credentials not found. Set AZURE_STORAGE_CONNECTION_STRING ' +\n    '(e.g. \"DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net\") ' +\n    'in the n8n container environment.'\n  );\n}\n\nfunction httpsGet(url) {\n  return new Promise((resolve, reject) => {\n    https.get(url, (res) => {\n      const chunks = [];\n      res.on('data', chunk => chunks.push(chunk));\n      res.on('end', () => resolve({\n        buffer: Buffer.concat(chunks),\n        statusCode: res.statusCode,\n        contentType: res.headers['content-type'] || 'application/octet-stream'\n      }));\n      res.on('error', reject);\n    }).on('error', reject);\n  });\n}\n\nfunction generateSasUrl(container, blobPath, sr = 'b', permissions = 'r') {\n  const now = new Date();\n  const expiry = new Date(now.getTime() + 3600000); // 1 hour\n  const sv = '2020-12-06';\n  const fmt = (d) => d.toISOString().replace(/\\.\\d{3}Z$/, 'Z');\n  const st = fmt(now);\n  const se = fmt(expiry);\n  const canonicalizedResource = `/blob/${accountName}/${container}/${blobPath}`;\n  // sv=2020-12-06: 16 fields, 15 \\n, NO trailing newline (signedEncryptionScope added)\n  const stringToSign = [permissions, st, se, canonicalizedResource, '', '', 'https', sv, sr, '', '', '', '', '', '', ''].join('\\n');\n  const key = Buffer.from(accountKey, 'base64');\n  const sig = crypto.createHmac('sha256', key).update(Buffer.from(stringToSign, 'utf8')).digest('base64');\n  // Build query string manually — URLSearchParams is not available in the n8n task runner VM sandbox\n  const qs = 'sv='  + encodeURIComponent(sv)\n           + '&sr=b'\n           + '&sp=r'\n           + '&st='  + encodeURIComponent(st)\n           + '&se='  + encodeURIComponent(se)\n           + '&spr=https'\n           + '&sig=' + encodeURIComponent(sig);\n  return `https://${accountName}.blob.core.windows.net/${container}/${blobPath}?${qs}`;\n}\n\nasync function fetchBlob(container, blobPath) {\n  const sasUrl = generateSasUrl(container, blobPath);\n  const { buffer, statusCode, contentType } = await httpsGet(sasUrl);\n  if (statusCode !== 200) {\n    throw new Error(`Azure Blob download failed HTTP ${statusCode} for ${container}/${blobPath}. Body: ${buffer.toString().substring(0, 300)}`);\n  }\n  return { buffer, contentType };\n}\n\nconst items = $input.all();\nconst result = [];\n\nfor (const item of items) {\n  // Pass through if binary already present (direct file upload path)\n  if (item.binary && Object.keys(item.binary).length > 0) {\n    result.push(item);\n    continue;\n  }\n\n  // Normalize: test webhook wraps body under item.json.body; production uses item.json directly\n  const bodyData  = item.json.body || item.json;\n  const blobPath  = bodyData.blobPath;\n  const blobFiles = bodyData.blobFiles;\n\n  if (!blobPath && !blobFiles) {\n    result.push(item);\n    continue;\n  }\n\n  if (!item.binary) item.binary = {};\n\n  if (blobPath) {\n    // Single-file mode: { \"blobPath\": \"folder/file.pdf\", \"azureContainer\": \"compliance\" }\n    const container = bodyData.azureContainer || 'compliance';\n    const { buffer, contentType } = await fetchBlob(container, blobPath);\n    const fileName = blobPath.split('/').pop();\n    item.binary.data = await this.helpers.prepareBinaryData(buffer, fileName, contentType);\n    item.json.azureBlobFetched = true;\n    item.json.originalFileName = fileName;\n  }\n\n  if (blobFiles) {\n    // Multi-file mode: { \"file0\": \"path.pdf\" } or { \"file0\": { \"blobPath\": \"...\", \"container\": \"...\" } }\n    for (const [fieldName, blobInfo] of Object.entries(blobFiles)) {\n      const bp = typeof blobInfo === 'string' ? blobInfo : blobInfo.blobPath;\n      const container = (typeof blobInfo === 'object' && blobInfo.container)\n        ? blobInfo.container\n        : (item.json.azureContainer || 'compliance');\n      const { buffer, contentType } = await fetchBlob(container, bp);\n      const fileName = bp.split('/').pop();\n      item.binary[fieldName] = await this.helpers.prepareBinaryData(buffer, fileName, contentType);\n    }\n    item.json.azureBlobFetched = true;\n  }\n\n  result.push(item);\n}\n\nreturn result;"
      },
      "id": "fetch-azure-blob-a",
      "name": "Fetch Azure Blob",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        460,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "const crypto = require('crypto');\nconst https = require('https');\n\n// Parse credentials from connection string (mirrors blobstorage.js approach)\nconst connectionString = $env.AZURE_STORAGE_CONNECTION_STRING || $env.AZURE_BLOB_CONNECTION_STRING;\nlet accountName, accountKey;\nif (connectionString) {\n  accountName = connectionString.match(/AccountName=([^;]+)/)?.[1];\n  accountKey  = connectionString.match(/AccountKey=([^;]+)/)?.[1];\n}\n// Fallback to individual env vars if connection string not set\nif (!accountName) accountName = $env.AZURE_STORAGE_ACCOUNT_NAME || 'unificdmpblob';\nif (!accountKey)  accountKey  = $env.AZURE_STORAGE_ACCOUNT_KEY;\n\nif (!accountKey) {\n  throw new Error(\n    'Azure credentials not found. Set AZURE_STORAGE_CONNECTION_STRING ' +\n    '(e.g. \"DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net\") ' +\n    'in the n8n container environment.'\n  );\n}\n\nfunction httpsGet(url) {\n  return new Promise((resolve, reject) => {\n    https.get(url, (res) => {\n      const chunks = [];\n      res.on('data', chunk => chunks.push(chunk));\n      res.on('end', () => resolve({\n        buffer: Buffer.concat(chunks),\n        statusCode: res.statusCode,\n        contentType: res.headers['content-type'] || 'application/octet-stream'\n      }));\n      res.on('error', reject);\n    }).on('error', reject);\n  });\n}\n\nfunction generateSasUrl(container, blobPath, sr = 'b', permissions = 'r') {\n  const now = new Date();\n  const expiry = new Date(now.getTime() + 3600000); // 1 hour\n  const sv = '2020-12-06';\n  const fmt = (d) => d.toISOString().replace(/\\.\\d{3}Z$/, 'Z');\n  const st = fmt(now);\n  const se = fmt(expiry);\n  const canonicalizedResource = `/blob/${accountName}/${container}/${blobPath}`;\n  // sv=2020-12-06: 16 fields, 15 \\n, NO trailing newline (signedEncryptionScope added)\n  const stringToSign = [permissions, st, se, canonicalizedResource, '', '', 'https', sv, sr, '', '', '', '', '', '', ''].join('\\n');\n  const key = Buffer.from(accountKey, 'base64');\n  const sig = crypto.createHmac('sha256', key).update(Buffer.from(stringToSign, 'utf8')).digest('base64');\n  // Build query string manually — URLSearchParams is not available in the n8n task runner VM sandbox\n  const qs = 'sv='  + encodeURIComponent(sv)\n           + '&sr=b'\n           + '&sp=r'\n           + '&st='  + encodeURIComponent(st)\n           + '&se='  + encodeURIComponent(se)\n           + '&spr=https'\n           + '&sig=' + encodeURIComponent(sig);\n  return `https://${accountName}.blob.core.windows.net/${container}/${blobPath}?${qs}`;\n}\n\nasync function fetchBlob(container, blobPath) {\n  const sasUrl = generateSasUrl(container, blobPath);\n  const { buffer, statusCode, contentType } = await httpsGet(sasUrl);\n  if (statusCode !== 200) {\n    throw new Error(`Azure Blob download failed HTTP ${statusCode} for ${container}/${blobPath}. Body: ${buffer.toString().substring(0, 300)}`);\n  }\n  return { buffer, contentType };\n}\n\nconst items = $input.all();\nconst result = [];\n\nfor (const item of items) {\n  // Pass through if binary already present (direct file upload path)\n  if (item.binary && Object.keys(item.binary).length > 0) {\n    result.push(item);\n    continue;\n  }\n\n  // Normalize: test webhook wraps body under item.json.body; production uses item.json directly\n  const bodyData  = item.json.body || item.json;\n  const blobPath  = bodyData.blobPath;\n  const blobFiles = bodyData.blobFiles;\n\n  if (!blobPath && !blobFiles) {\n    result.push(item);\n    continue;\n  }\n\n  if (!item.binary) item.binary = {};\n\n  if (blobPath) {\n    // Single-file mode: { \"blobPath\": \"folder/file.pdf\", \"azureContainer\": \"compliance\" }\n    const container = bodyData.azureContainer || 'compliance';\n    const { buffer, contentType } = await fetchBlob(container, blobPath);\n    const fileName = blobPath.split('/').pop();\n    item.binary.data = await this.helpers.prepareBinaryData(buffer, fileName, contentType);\n    item.json.azureBlobFetched = true;\n    item.json.originalFileName = fileName;\n  }\n\n  if (blobFiles) {\n    // Multi-file mode: { \"file0\": \"path.pdf\" } or { \"file0\": { \"blobPath\": \"...\", \"container\": \"...\" } }\n    for (const [fieldName, blobInfo] of Object.entries(blobFiles)) {\n      const bp = typeof blobInfo === 'string' ? blobInfo : blobInfo.blobPath;\n      const container = (typeof blobInfo === 'object' && blobInfo.container)\n        ? blobInfo.container\n        : (item.json.azureContainer || 'compliance');\n      const { buffer, contentType } = await fetchBlob(container, bp);\n      const fileName = bp.split('/').pop();\n      item.binary[fieldName] = await this.helpers.prepareBinaryData(buffer, fileName, contentType);\n    }\n    item.json.azureBlobFetched = true;\n  }\n\n  result.push(item);\n}\n\nreturn result;"
      },
      "id": "fetch-azure-blob-a",
      "name": "Fetch Azure Blob",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        460,
        300
      ]
    }
  ],
  "connections": {
    "Webhook: Extract Content": {
      "main": [
        [
          {
            "node": "Fetch Azure Blob",
            "type": "main",
            "index": 0
          },
          {
            "node": "Services Health Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Binary": {
      "main": [
        [
          {
            "node": "Merge Health & Data",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error: No File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Error: No File": {
      "main": [
        [
          {
            "node": "Respond Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Binary Filename": {
      "main": [
        [
          {
            "node": "Write Temp File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write Temp File": {
      "main": [
        [
          {
            "node": "Switch by File Type",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch by File Type": {
      "main": [
        [
          {
            "node": "Extract Images",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Convert PPTX to PDF",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Convert DOCX to PDF",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Copy Single Image",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Convert Excel to PDF",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error: Unsupported Type",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Convert PPTX to PDF": {
      "main": [
        [
          {
            "node": "Extract Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Convert DOCX to PDF": {
      "main": [
        [
          {
            "node": "Extract Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Images": {
      "main": [
        [
          {
            "node": "List Generated Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Copy Single Image": {
      "main": [
        [
          {
            "node": "List Generated Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Convert Excel to PDF": {
      "main": [
        [
          {
            "node": "Extract Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Error: Unsupported Type": {
      "main": [
        [
          {
            "node": "Respond Error Type",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "List Generated Images": {
      "main": [
        [
          {
            "node": "Prepare Generated File List",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Generated File List": {
      "main": [
        [
          {
            "node": "OCR Processing",
            "type": "main",
            "index": 0
          },
          {
            "node": "Florence Vision Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OCR Processing": {
      "main": [
        [
          {
            "node": "Merge Vision & OCR",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Florence Vision Analysis": {
      "main": [
        [
          {
            "node": "Merge Vision & OCR",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Vision & OCR": {
      "main": [
        [
          {
            "node": "Parse OCR & Vision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse OCR & Vision": {
      "main": [
        [
          {
            "node": "Aggregate Pages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Pages": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Services Health Check": {
      "main": [
        [
          {
            "node": "Check Health Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Health Status": {
      "main": [
        [
          {
            "node": "Merge Health & Data",
            "type": "main",
            "index": 1
          }
        ],
        [
          {
            "node": "Set Service Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Service Error": {
      "main": [
        [
          {
            "node": "Respond Error Service",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Health & Data": {
      "main": [
        [
          {
            "node": "Set Binary Filename",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Azure Blob": {
      "main": [
        [
          {
            "node": "Validate Binary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2026-02-09T00:00:00.000Z",
  "versionId": "1"
}