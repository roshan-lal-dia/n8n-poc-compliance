{
  "name": "Workflow C2: Audit Worker (Background Processor)",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "seconds",
              "secondsInterval": 10
            }
          ]
        }
      },
      "id": "0fb56361-5e41-42c2-9357-72b165d81396",
      "name": "Cron: Every 10s",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        0,
        0
      ]
    },
    {
      "parameters": {
        "operation": "pop",
        "list": "audit_job_queue",
        "tail": true,
        "propertyName": "output",
        "options": {}
      },
      "id": "02204c41-30e3-435a-a890-ccc2d32f54c8",
      "name": "Dequeue Job from Redis",
      "type": "n8n-nodes-base.redis",
      "typeVersion": 1,
      "position": [
        224,
        0
      ],
      "credentials": {
        "redis": {
          "id": "K8jo4houPYYpv2hq",
          "name": "redis-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const result = $input.first().json;\n\n// If queue is empty, return empty array to stop execution\nif (!result || !result.output) {\n  return [];\n}\n\n// Handle both string and object output from Redis\nlet job;\nif (typeof result.output === 'string') {\n  job = JSON.parse(result.output);\n} else if (typeof result.output === 'object') {\n  job = result.output;\n} else {\n  console.error('Unexpected output type:', typeof result.output);\n  return [];\n}\n\nreturn [{ json: job }];"
      },
      "id": "29bdc0ed-86fc-45b8-8462-388a68b9e10d",
      "name": "Parse Job (Exit if Empty)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE audit_sessions SET status = 'processing' WHERE session_id = '{{ $json.sessionId }}'::uuid;",
        "options": {}
      },
      "id": "6c51bb18-24a4-4694-805e-338b10b20305",
      "name": "Update Session: Processing",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        672,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO audit_logs (session_id, step_name, status, message, percentage)\nVALUES ('{{ $('Parse Job (Exit if Empty)').first().json.sessionId }}'::uuid, 'processing', 'in_progress', 'Starting audit execution', 5);",
        "options": {}
      },
      "id": "64081a31-ed75-4df8-b9f7-a366207ef97e",
      "name": "Log: Start Processing",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        880,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Split into one execution per question\n// Get job data from Parse Job node (not from Log: Start Processing which is INSERT)\nconst job = $('Parse Job (Exit if Empty)').first().json;\n\nreturn job.questions.map((q, index) => ({\n  json: {\n    sessionId: job.sessionId,\n    domain: job.domain,\n    qId: q.q_id,\n    evidenceFiles: q.evidence_files,\n    fileMap: job.fileMap,\n    questionIndex: index,\n    totalQuestions: job.questions.length\n  }\n}));"
      },
      "id": "c67828cc-06cd-4e80-91ec-903cf11ba750",
      "name": "Split by Question",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1104,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO audit_logs (session_id, q_id, step_name, status, message, percentage)\nVALUES (\n  '{{ $json.sessionId }}'::uuid,\n  '{{ $json.qId }}',\n  'extracting',\n  'in_progress',\n  '{{ \"Processing question \" + ($json.questionIndex + 1) + \" of \" + $json.totalQuestions }}',\n  {{ 10 + Math.floor(($json.questionIndex / $json.totalQuestions) * 80) }}\n);",
        "options": {}
      },
      "id": "9358544b-079f-4d7e-ba62-def8295440b2",
      "name": "Log: Question Start",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        1328,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  file_hash,\n  extracted_data,\n  filename,\n  file_size_bytes\nFROM audit_evidence\nWHERE session_id = '{{ $('Split by Question').first().json.sessionId }}'::uuid \n  AND q_id = '{{ $('Split by Question').first().json.qId }}'\n  AND file_hash = ANY(ARRAY[{{ $('Split by Question').first().json.evidenceFiles.map(f => \"'\" + f.hash + \"'\").join(',') }}]::text[])\nUNION ALL\nSELECT \n  'nocache' as file_hash,\n  NULL as extracted_data,\n  NULL as filename,\n  NULL as file_size_bytes\nWHERE NOT EXISTS (\n  SELECT 1 FROM audit_evidence\n  WHERE session_id = '{{ $('Split by Question').first().json.sessionId }}'::uuid \n    AND q_id = '{{ $('Split by Question').first().json.qId }}'\n    AND file_hash = ANY(ARRAY[{{ $('Split by Question').first().json.evidenceFiles.map(f => \"'\" + f.hash + \"'\").join(',') }}]::text[])\n);",
        "options": {}
      },
      "id": "bd0ab794-c4d3-42cd-ad31-20200a03917d",
      "name": "Check Evidence Cache",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        1552,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const questionData = $('Split by Question').first().json;\nconst cacheResults = $input.all();\n\nconsole.log('=== PREPARE FILES DEBUG ===');\nconsole.log('Cache results count:', cacheResults.length);\n\n// Extract cached evidence - filter out 'nocache' marker\nconst cachedEvidence = cacheResults\n  .map(item => item.json)\n  .filter(item => {\n    if (item.file_hash === 'nocache') {\n      return false;\n    }\n    return item && item.file_hash && item.extracted_data;\n  });\n\nconsole.log('Valid cached evidence count:', cachedEvidence.length);\n\n// Determine which files need extraction\nconst cachedHashes = new Set(cachedEvidence.map(e => e.file_hash));\nconst filesToExtract = questionData.evidenceFiles.filter(f => !cachedHashes.has(f.hash));\n\nconsole.log('Files to extract:', filesToExtract.length);\n\n// Store cached evidence for later\nconst cachedEvidenceData = cachedEvidence.map(cached => ({\n  hash: cached.file_hash,\n  filename: cached.filename,\n  extractedData: cached.extracted_data,\n  fileSize: cached.file_size_bytes,\n  fromCache: true\n}));\n\n// Prepare files for extraction (one item per file)\nconst filesToProcess = [];\nfor (const fileInfo of filesToExtract) {\n  const fileData = questionData.fileMap[fileInfo.fieldName];\n  if (!fileData) {\n    throw new Error(`File fieldName \"${fileInfo.fieldName}\" not found in fileMap. Available: ${Object.keys(questionData.fileMap).join(', ')}`);\n  }\n  \n  if (!fileData.binaryData) {\n    throw new Error(`No binary data found for ${fileData.fileName}. File may not have been uploaded correctly.`);\n  }\n  \n  const actualSize = Buffer.from(fileData.binaryData, 'base64').length;\n  console.log(`Prepared ${fileData.fileName}: ${actualSize} bytes`);\n  \n  filesToProcess.push({\n    json: {\n      sessionId: questionData.sessionId,\n      qId: questionData.qId,\n      domain: questionData.domain,\n      hash: fileInfo.hash,\n      filename: fileData.fileName,\n      fileSize: actualSize,\n      mimeType: fileData.mimeType,\n      cachedEvidence: cachedEvidenceData\n    },\n    binary: {\n      data: {\n        data: fileData.binaryData,\n        mimeType: fileData.mimeType,\n        fileName: fileData.fileName,\n        fileExtension: fileData.fileName.split('.').pop()\n      }\n    }\n  });\n}\n\nif (filesToProcess.length === 0) {\n  console.log('No files to extract, returning cached-only result');\n  return[{\n    json: {\n      sessionId: questionData.sessionId,\n      qId: questionData.qId,\n      domain: questionData.domain,\n      allEvidence: cachedEvidenceData,\n      newExtractions: [],\n      totalEvidence: cachedEvidenceData.length,\n      fromCache: cachedEvidenceData.length,\n      justExtracted: 0\n    }\n  }];\n}\n\nreturn filesToProcess;"
      },
      "id": "3bc35ea3-4258-4ecf-8bd5-9185e16dabec",
      "name": "Prepare Files for Extraction",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1760,
        0
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "needs-extraction",
              "leftValue": "={{ $json.binary !== undefined && $json.binary.data !== undefined }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "true"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "check-extraction-needed",
      "name": "Check if Extraction Needed",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        1984,
        0
      ]
    },
    {
      "parameters": {
        "url": "http://n8n:5678/webhook/extract",
        "method": "POST",
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "data"
            }
          ]
        },
        "options": {
          "timeout": 300000,
          "response": {
            "response": {
              "neverError": false,
              "responseFormat": "json",
              "outputPropertyName": "data"
            }
          }
        }
      },
      "id": "call-workflow-a-extraction",
      "name": "Call Workflow A: Extract",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2208,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Combine extracted results with cached evidence\nconst currentItems = $input.all();\nconst preparedItems = $('Prepare Files for Extraction').all();\n\n// Check if this is the FALSE path (no extraction needed)\nif (currentItems.length > 0 && currentItems[0].json.allEvidence !== undefined) {\n  // Already has the complete structure, pass through\n  return currentItems;\n}\n\n// This is the TRUE path (extraction happened)\n// Get cached evidence from first prepared item\nconst cachedEvidence = preparedItems[0].json.cachedEvidence || [];\nconst firstPrepared = preparedItems[0].json;\n\nconst allEvidence = [...cachedEvidence];\nconst newExtractions = [];\n\n// Process each extraction result\nfor (let i = 0; i < currentItems.length; i++) {\n  const extractedData = currentItems[i].json;\n  const preparedData = preparedItems[i].json;\n  \n  // Validate that extraction returned proper data\n  if (!extractedData.fullDocument && !extractedData.text) {\n    console.error('Extraction failed for file:', preparedData.filename);\n    console.error('Got data:', JSON.stringify(extractedData));\n    \n    // Use empty extraction as fallback\n    extractedData.fullDocument = `[Extraction failed for ${preparedData.filename}]`;\n    extractedData.totalPages = 0;\n    extractedData.totalWords = 0;\n    extractedData.hasDiagrams = false;\n  }\n  \n  allEvidence.push({\n    hash: preparedData.hash,\n    filename: preparedData.filename,\n    extractedData: extractedData,\n    fileSize: preparedData.fileSize,\n    fromCache: false\n  });\n  \n  newExtractions.push({\n    hash: preparedData.hash,\n    filename: preparedData.filename,\n    extractedData: extractedData,\n    fileSize: preparedData.fileSize\n  });\n}\n\nreturn [{\n  json: {\n    sessionId: firstPrepared.sessionId,\n    qId: firstPrepared.qId,\n    domain: firstPrepared.domain,\n    allEvidence: allEvidence,\n    newExtractions: newExtractions,\n    totalEvidence: allEvidence.length,\n    fromCache: cachedEvidence.length,\n    justExtracted: newExtractions.length\n  }\n}];"
      },
      "id": "combine-extraction-results",
      "name": "Combine Extraction Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2432,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Store newly extracted evidence to database\nconst data = $input.first().json;\nconst insertStatements = [];\n\n// Safety check\nif (!data || !data.newExtractions || !Array.isArray(data.newExtractions)) {\n  return [];\n}\n\nlet order = 1;\nfor (const evidence of data.newExtractions) {\n  insertStatements.push({\n    sessionId: data.sessionId,\n    qId: data.qId,\n    domain: data.domain,\n    filename: evidence.filename,\n    fileHash: evidence.hash,\n    fileSize: evidence.fileSize,\n    extractedData: JSON.stringify(evidence.extractedData),\n    evidenceOrder: order++\n  });\n}\n\n// If nothing to insert, return empty array to skip DB insert\nif (insertStatements.length === 0) {\n  return [];\n}\n\nreturn insertStatements.map(s => ({ json: s }));"
      },
      "id": "886fff62-80ec-47e3-8a27-d08c4e0177db",
      "name": "Prepare Evidence Inserts",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2656,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO audit_evidence (session_id, q_id, domain, filename, file_hash, file_size_bytes, extracted_data, evidence_order)\nVALUES (\n  '{{ $json.sessionId }}'::uuid,\n  '{{ $json.qId }}',\n  '{{ $json.domain }}',\n  '{{ $json.filename }}',\n  '{{ $json.fileHash }}',\n  {{ $json.fileSize }},\n  '{{ $json.extractedData }}'::jsonb,\n  {{ $json.evidenceOrder }}\n)\nON CONFLICT (session_id, q_id, file_hash) DO NOTHING;",
        "options": {}
      },
      "id": "d0542fce-3c7a-49e8-b21e-749b5ed1c09e",
      "name": "Store Evidence to DB",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        2880,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Consolidate all evidence for this question with size limits\nconst evidenceData = $('Combine Extraction Results').first().json;\n\n// Safety check\nif (!evidenceData || !evidenceData.allEvidence || !Array.isArray(evidenceData.allEvidence)) {\n  throw new Error('No evidence data available from extraction step');\n}\n\nlet combinedText = '';\nconst sourceFiles = [];\nlet totalPages = 0;\nlet totalWords = 0;\n\nfor (const evidence of evidenceData.allEvidence) {\n  const extracted = evidence.extractedData || {};\n  const fullText = extracted.fullDocument || extracted.text || '';\n  \n  // Per-file limit: 50,000 characters\n  const truncated = fullText.substring(0, 50000);\n  \n  combinedText += `\\n\\n=== Evidence File: ${evidence.filename} ===\\n${truncated}`;\n  \n  sourceFiles.push({\n    filename: evidence.filename,\n    hash: evidence.hash,\n    pages: extracted.totalPages || 0,\n    words: extracted.totalWords || 0,\n    diagrams: extracted.hasDiagrams || false,\n    truncated: fullText.length > 50000,\n    fromCache: evidence.fromCache\n  });\n  \n  totalPages += extracted.totalPages || 0;\n  totalWords += extracted.totalWords || 0;\n}\n\n// Overall limit: 200,000 characters\nif (combinedText.length > 200000) {\n  combinedText = combinedText.substring(0, 200000) + '\\n\\n[Evidence truncated at 200,000 characters]';\n}\n\nreturn [{\n  json: {\n    sessionId: evidenceData.sessionId,\n    qId: evidenceData.qId,\n    domain: evidenceData.domain,\n    evidenceText: combinedText,\n    evidenceLength: combinedText.length,\n    sourceFiles: sourceFiles,\n    totalPages: totalPages,\n    totalWords: totalWords\n  }\n}];"
      },
      "id": "a93c7dd0-8137-49be-bcff-8db5e7dbf9e1",
      "name": "Consolidate Evidence Text",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3104,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT q_id, question_text, prompt_instructions, domain\nFROM audit_questions\nWHERE q_id = '{{ $('Consolidate Evidence Text').first().json.qId }}';",
        "options": {}
      },
      "id": "52da4749-ecb2-4ef1-a311-3493fff52190",
      "name": "Load Question",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        3328,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE audit_logs SET step_name = 'searching', percentage = {{ 30 + Math.floor(($('Split by Question').first().json.questionIndex / $('Split by Question').first().json.totalQuestions) * 50) }}\nWHERE session_id = '{{ $('Consolidate Evidence Text').first().json.sessionId }}'::uuid AND q_id = '{{ $('Consolidate Evidence Text').first().json.qId }}' AND step_name = 'extracting';",
        "options": {}
      },
      "id": "3068bcbd-badf-4151-821e-2a0d9c1a53c9",
      "name": "Update Log: Searching",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        3552,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare embedding request for question + instructions\n// Get question data from Load Question node (not from Update Log which is UPDATE)\nconst question = $('Load Question').first().json;\n\nconst queryText = `${question.question_text}\\n\\n${question.prompt_instructions || ''}`;\n\nreturn [{\n  json: {\n    questionId: question.q_id,\n    questionText: question.question_text,\n    instructions: question.prompt_instructions,\n    questionDomain: question.domain,\n    queryText: queryText\n  }\n}];"
      },
      "id": "9656f449-b95f-4528-8ec6-0f7efdadb4fd",
      "name": "Prepare Question for Embedding",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3552,
        0
      ]
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/embeddings",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\n  \"model\": \"nomic-embed-text\",\n  \"prompt\": $json.queryText\n} }}",
        "options": {
          "timeout": 30000
        }
      },
      "id": "call-ollama-embedding",
      "name": "Ollama: Generate Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3776,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Extract embedding from Ollama response\nconst ollamaResponse = $input.first().json;\nconst questionData = $('Prepare Question for Embedding').first().json;\n\n// Safety check\nif (!ollamaResponse || !ollamaResponse.embedding) {\n  throw new Error('Ollama did not return embedding. Response: ' + JSON.stringify(ollamaResponse));\n}\n\nreturn [{\n  json: {\n    questionId: questionData.questionId,\n    questionText: questionData.questionText,\n    instructions: questionData.instructions,\n    questionDomain: questionData.questionDomain,\n    embedding: ollamaResponse.embedding\n  }\n}];"
      },
      "id": "extract-embedding",
      "name": "Extract Embedding",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4000,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Prepare Qdrant search payload\nconst questionData = $input.first().json;\nconst evidenceData = $('Consolidate Evidence Text').first().json;\n\nconst searchPayload = {\n  vector: questionData.embedding,\n  limit: 5,\n  with_payload: true\n};\n\n// Add domain filter if specified\nif (evidenceData.domain && evidenceData.domain !== 'General') {\n  searchPayload.filter = {\n    must: [\n      {\n        key: 'domain',\n        match: { value: evidenceData.domain }\n      }\n    ]\n  };\n}\n\nreturn [{\n  json: {\n    sessionId: evidenceData.sessionId,\n    qId: evidenceData.qId,\n    searchPayload: searchPayload,\n    questionData: questionData,\n    evidenceData: evidenceData\n  }\n}];"
      },
      "id": "0901ad33-590c-4a51-8a86-df519c293812",
      "name": "Prepare RAG Search",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4224,
        0
      ]
    },
    {
      "parameters": {
        "url": "http://qdrant:6333/collections/compliance_standards/points/search",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.searchPayload }}",
        "options": {
          "timeout": 30000
        }
      },
      "id": "call-qdrant-search",
      "name": "Qdrant: Search Standards",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4448,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Format RAG search results\nconst qdrantResponse = $input.first().json;\nconst contextData = $('Prepare RAG Search').first().json;\n\n// Safety check\nif (!qdrantResponse || !qdrantResponse.result || !Array.isArray(qdrantResponse.result)) {\n  console.warn('Qdrant returned no results:', qdrantResponse);\n  return [{\n    json: {\n      sessionId: contextData.sessionId,\n      qId: contextData.qId,\n      ragSources: [],\n      totalSources: 0\n    }\n  }];\n}\n\nconst ragSources = qdrantResponse.result.map((hit, index) => ({\n  rank: index + 1,\n  standardName: hit.payload.standardName,\n  chunkIndex: hit.payload.chunkIndex,\n  relevanceScore: hit.score,\n  text: hit.payload.text,\n  excerpt: hit.payload.text.substring(0, 600),\n  metadata: hit.payload.metadata\n}));\n\nreturn [{\n  json: {\n    sessionId: contextData.sessionId,\n    qId: contextData.qId,\n    ragSources: ragSources,\n    totalSources: ragSources.length\n  }\n}];"
      },
      "id": "format-rag-results",
      "name": "Format RAG Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4672,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Build comprehensive AI prompt\nconst questionData = $('Extract Embedding').first().json;\nconst evidenceData = $('Consolidate Evidence Text').first().json;\nconst ragData = $('Format RAG Results').first().json;\n\n// Format RAG sources section\nconst ragSources = ragData.ragSources || [];\nconst ragSection = ragSources.length > 0 \n  ? ragSources.map((source, i) => \n      `${i+1}. [${source.standardName}] (Relevance: ${source.relevanceScore.toFixed(2)})\\n${source.excerpt}\\n`\n    ).join('\\n')\n  : 'No specific compliance standards found in knowledge base. Evaluate based on general industry best practices.';\n\n// Build master prompt\nconst prompt = `COMPLIANCE AUDIT EVALUATION\n\nQUESTION: ${questionData.questionText}\n\nINSTRUCTIONS: ${questionData.instructions || 'Evaluate based on industry best practices and standards.'}\n\nRELEVANT COMPLIANCE STANDARDS:\n${ragSection}\n\nEVIDENCE FROM SUBMITTED DOCUMENTS:\n${evidenceData.evidenceText}\n\n---\n\nEvaluate compliance with the question based on the provided evidence and standards.\nRespond in JSON format with the following structure:\n{\n  \"compliant\": boolean,\n  \"score\": 0-100,\n  \"confidence\": 0-100,\n  \"findings\": \"detailed description of what was found\",\n  \"evidence_summary\": \"specific references to evidence that supports the evaluation\",\n  \"gaps\": [\"list of missing or insufficient elements\"],\n  \"recommendations\": [\"actionable improvements\"]\n}`;\n\nreturn [{\n  json: {\n    sessionId: evidenceData.sessionId,\n    qId: evidenceData.qId,\n    prompt: prompt,\n    promptLength: prompt.length,\n    ragSources: ragSources,\n    sourceFiles: evidenceData.sourceFiles\n  }\n}];"
      },
      "id": "b29e0ebb-9cf8-41a8-8ff9-bec6604effcf",
      "name": "Build AI Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4896,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE audit_logs SET step_name = 'evaluating', percentage = {{ 85 + Math.floor(($('Split by Question').first().json.questionIndex / $('Split by Question').first().json.totalQuestions) * 10) }}\nWHERE session_id = '{{ $('Build AI Prompt').first().json.sessionId }}'::uuid AND q_id = '{{ $('Build AI Prompt').first().json.qId }}' AND step_name = 'searching';",
        "options": {}
      },
      "id": "9793deff-23f9-42cd-a514-79e52f694efb",
      "name": "Update Log: Evaluating",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        5120,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/generate",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\n  \"model\": \"llama3.2\",\n  \"prompt\": $('Build AI Prompt').first().json.prompt,\n  \"format\": \"json\",\n  \"stream\": false,\n  \"options\": {\n    \"temperature\": 0.3,\n    \"num_ctx\": 32768,\n    \"num_predict\": 2000\n  }\n} }}",
        "options": {
          "timeout": 600000
        }
      },
      "id": "aeba3cde-03e9-45ee-8c14-65d147275e87",
      "name": "Ollama: Evaluate Compliance",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        5344,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Parse and validate AI response\nconst aiResponse = $input.first().json;\nconst promptData = $('Build AI Prompt').first().json;\n\nconst rawResponse = aiResponse.response;\nlet evaluation;\n\ntry {\n  evaluation = JSON.parse(rawResponse);\n  \n  // Validate required fields\n  if (!evaluation.hasOwnProperty('compliant')) evaluation.compliant = false;\n  if (!evaluation.hasOwnProperty('score')) evaluation.score = 0;\n  if (!evaluation.hasOwnProperty('confidence')) evaluation.confidence = 0;\n  if (!evaluation.findings) evaluation.findings = 'No findings provided';\n  if (!evaluation.gaps) evaluation.gaps = [];\n  if (!evaluation.recommendations) evaluation.recommendations = [];\n  \n} catch (e) {\n  // Fallback on parse failure\n  evaluation = {\n    compliant: false,\n    score: 0,\n    confidence: 0,\n    findings: 'AI response parsing failed: ' + e.message,\n    evidence_summary: '',\n    gaps: ['Unable to evaluate due to response format error'],\n    recommendations: ['Review question prompt and try again']\n  };\n}\n\nreturn [{\n  json: {\n    sessionId: promptData.sessionId,\n    qId: promptData.qId,\n    evaluation: evaluation,\n    rawResponse: rawResponse,\n    ragSources: promptData.ragSources,\n    sourceFiles: promptData.sourceFiles,\n    promptLength: promptData.promptLength\n  }\n}];"
      },
      "id": "parse-ai-response",
      "name": "Parse AI Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5568,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO audit_logs (session_id, q_id, step_name, status, ai_response, message, percentage)\nVALUES (\n  '{{ $json.sessionId }}'::uuid,\n  '{{ $json.qId }}',\n  'completed',\n  'success',\n  '{{ JSON.stringify($json.evaluation) }}'::jsonb,\n  '{{ \"Question evaluated successfully (Score: \" + $json.evaluation.score + \")\" }}',\n  {{ 95 + Math.floor(($('Split by Question').first().json.questionIndex / $('Split by Question').first().json.totalQuestions) * 5) }}\n);",
        "options": {}
      },
      "id": "8c57a6c0-3e26-4a15-94f4-85d35ca3f1d4",
      "name": "Log Evaluation Result",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        5792,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// After all questions complete, aggregate scores\nconst allResults = $input.all();\n\n// Safety check\nif (!allResults || allResults.length === 0) {\n  throw new Error('No question results to aggregate');\n}\n\n// Calculate average score\nconst scores = allResults.map(r => r.json?.evaluation?.score || 0);\nconst avgScore = scores.reduce((a, b) => a + b, 0) / scores.length;\n\n// Get session ID from first result\nconst sessionId = allResults[0].json.sessionId;\n\nreturn [{\n  json: {\n    sessionId: sessionId,\n    overallScore: Math.round(avgScore * 100) / 100,\n    totalQuestions: allResults.length,\n    questionResults: allResults.map(r => ({\n      qId: r.json.qId,\n      score: r.json?.evaluation?.score || 0,\n      compliant: r.json?.evaluation?.compliant || false\n    }))\n  }\n}];"
      },
      "id": "06806e4d-fd6b-4ddb-acf7-30416ce9afc7",
      "name": "Aggregate Scores",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        6016,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE audit_sessions SET\n  status = 'completed',\n  completed_at = NOW(),\n  answered_questions = {{ $json.totalQuestions }},\n  overall_compliance_score = {{ $json.overallScore }}\nWHERE session_id = '{{ $json.sessionId }}'::uuid;",
        "options": {}
      },
      "id": "b598f4c0-ddae-4b44-b0d7-baf3e7288fa9",
      "name": "Update Session: Completed",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        6240,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO audit_logs (session_id, step_name, status, message, percentage)\nVALUES ('{{ $('Aggregate Scores').first().json.sessionId }}'::uuid, 'completed', 'success', '{{ \"All \" + $('Aggregate Scores').first().json.totalQuestions + \" questions evaluated. Overall score: \" + $('Aggregate Scores').first().json.overallScore }}', 100);",
        "options": {}
      },
      "id": "87c2fa21-5ebd-465d-ae8c-63610a41c1c5",
      "name": "Log: Final Completion",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        6464,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// No cleanup needed - binary data stays in n8n\nconst job = $('Parse Job (Exit if Empty)').first().json;\n\nreturn [{\n  json: {\n    sessionId: job.sessionId,\n    cleanupComplete: true\n  }\n}];"
      },
      "id": "661ce606-1194-4010-a931-d67313cbf4f6",
      "name": "Cleanup: Temp Files",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        6688,
        0
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "DELETE FROM audit_evidence WHERE session_id = '{{ $('Cleanup: Temp Files').first().json.sessionId }}'::uuid;",
        "options": {}
      },
      "id": "0898354c-1d66-4fad-a6e5-0d60b5e977f7",
      "name": "Cleanup: Evidence DB",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        6912,
        0
      ],
      "credentials": {
        "postgres": {
          "id": "3ME8TvhWnolXkgqg",
          "name": "postgres-compliance"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Cron: Every 10s": {
      "main": [
        [
          {
            "node": "Dequeue Job from Redis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dequeue Job from Redis": {
      "main": [
        [
          {
            "node": "Parse Job (Exit if Empty)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Job (Exit if Empty)": {
      "main": [
        [
          {
            "node": "Update Session: Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Session: Processing": {
      "main": [
        [
          {
            "node": "Log: Start Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log: Start Processing": {
      "main": [
        [
          {
            "node": "Split by Question",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split by Question": {
      "main": [
        [
          {
            "node": "Log: Question Start",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log: Question Start": {
      "main": [
        [
          {
            "node": "Check Evidence Cache",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Evidence Cache": {
      "main": [
        [
          {
            "node": "Prepare Files for Extraction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Files for Extraction": {
      "main": [
        [
          {
            "node": "Check if Extraction Needed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check if Extraction Needed": {
      "main": [
        [
          {
            "node": "Call Workflow A: Extract",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Combine Extraction Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Workflow A: Extract": {
      "main": [
        [
          {
            "node": "Combine Extraction Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine Extraction Results": {
      "main": [
        [
          {
            "node": "Prepare Evidence Inserts",
            "type": "main",
            "index": 0
          },
          {
            "node": "Consolidate Evidence Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Evidence Inserts": {
      "main": [
        [
          {
            "node": "Store Evidence to DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Evidence to DB": {
      "main": []
    },
    "Consolidate Evidence Text": {
      "main": [
        [
          {
            "node": "Load Question",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Load Question": {
      "main": [
        [
          {
            "node": "Update Log: Searching",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Log: Searching": {
      "main": [
        [
          {
            "node": "Prepare Question for Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Question for Embedding": {
      "main": [
        [
          {
            "node": "Ollama: Generate Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama: Generate Embedding": {
      "main": [
        [
          {
            "node": "Extract Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Embedding": {
      "main": [
        [
          {
            "node": "Prepare RAG Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare RAG Search": {
      "main": [
        [
          {
            "node": "Qdrant: Search Standards",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Qdrant: Search Standards": {
      "main": [
        [
          {
            "node": "Format RAG Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format RAG Results": {
      "main": [
        [
          {
            "node": "Build AI Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build AI Prompt": {
      "main": [
        [
          {
            "node": "Update Log: Evaluating",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Log: Evaluating": {
      "main": [
        [
          {
            "node": "Ollama: Evaluate Compliance",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama: Evaluate Compliance": {
      "main": [
        [
          {
            "node": "Parse AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse AI Response": {
      "main": [
        [
          {
            "node": "Log Evaluation Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log Evaluation Result": {
      "main": [
        [
          {
            "node": "Aggregate Scores",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Scores": {
      "main": [
        [
          {
            "node": "Update Session: Completed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Session: Completed": {
      "main": [
        [
          {
            "node": "Log: Final Completion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log: Final Completion": {
      "main": [
        [
          {
            "node": "Cleanup: Temp Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Cleanup: Temp Files": {
      "main": [
        [
          {
            "node": "Cleanup: Evidence DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "binaryMode": "separate",
    "availableInMCP": false
  },
  "versionId": "80a94a0a-0573-48de-83f0-5110ba570096",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "633797609a32887ee9bd2dd2130a91be77c69c0480540cd258fc427bbd7f9ad9"
  },
  "id": "f3w2uNQSKQe-yfuB48r8S",
  "tags": []
}